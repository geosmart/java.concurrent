性能与可伸缩性
---
1. 线程的最主要的目的是提高程序的运行性能。线程可以使程序更加充分的发挥系统的可用处理能力，从而提高系统的资源利用率。
2. 此外，线程还可以使程序在运行现有任务的情况下立即开始处理新的任务，从而提高系统的响应性；

1. 本章将介绍各种分析、监测以及提升并发程序性能的技术，
2. 但许多提升性能的技术同样会增加`复杂性`，因此也就增加了在`安全性`和`活跃性`上发生失败的风险；
3. 更糟糕的是，虽然某些技术的初衷是`提升性能`，但事实上缺最终于最初的目标背道而驰，或者又带来了其他的`新的性能问题`；
4. 虽然我们希望获得更好的性能，提升性能总会令人满意，但始终要把`安全性`放在第一位；
5. 首先要保证程序能`正确运行`，然后仅当程序的`性能需求`和测试结果要求程序执行得更快时，才应该设法提高它的运行速度；
6. 在设计并发的应用程序时，最主要的考虑因素通常不是将程序的性能提升至极限；

# 对性能的思考
>提升性能意味着用更少的资源做更多的事情。
1. `资源`的含义很广：对于一个给定的操作，通常会缺乏某种特定的资源：如`CPU时钟周期`、`内存`、`网络带宽`、`I/O带宽`、`数据库请求`、`磁盘空间`以及其他资源。
2. 当操作性能由于`某种特定的资源`而受到限制时，我们通常将该操作称为`资源密集型的操作`，例如，`CPU密集型`、`数据库密集型`等；
3. 尽管使用多个线程的目标是提升整体性能，但与单线程相比，多线程总会引入一些`额外的开销`：`线程之间的协调`（如加锁、触发信号以及内存同步等），增加的`上下文切换`，`线程的创建与销毁`，以及`线程的调度`等。
4. 如果过度的使用线程，那么这些`开销`甚至会超过由于提高`吞吐量`、`响应性`或者`计算能力`所带来的性能提升；

## 性能与可伸缩性
## 评估各种性能权衡因素
1. 避免不成熟的优化。首先使程序正确，然后提供运行速度；
2. 在使某个方案比其他方案`更快`之前，首先问自己一些问题：
   1. `更快`的含义是什么?
   2. 该方法在什么`条件`下运行更快？在低负载还是高负载情况下，大数据集还是小数据集？能否通过测试结果来验证你的答案？
   3. 这些条件在运行环境中的发生频率？能否通过测试结果来验证你的答案？
   4. 在其让不同条件的环境中能否使用这里的代码？
   5. 在实现这种性能提升时需要付出哪些隐含的代价，例如增加开发风险或维护开销？这种权衡是否合适？
3. 对性能的提升可能是并发错误的最大来源；
4. 由于并发错误是最难追踪和消除的错误，因此对于任何可能会引入这类的错误的措施，都需要谨`慎实施`；
5. 在对性能进行调优时，一定要有`明确的性能需求`；
6. `以测试为基准，不要猜测`；

# Amdahl定律
1. 在有些问题中，如果可用资源越多，那么问题的解决速度就越快；例如参与收割庄稼的工人越多，那么就能越快的完成收割工作；
2. 有些任务本质上是串行的，例如即使增加再多的工人也不能增加作物的生长速度；
3. 如果使用线程主要是为了发挥多个处理器的处理能力，那么就必须对问题进行合理的并行分解，并使得程序能有效的使用这种潜在的并行能力；
4. 大多数并发程序都与农业耕作有着许多相似之处；他们都是由一系列的并行工作和串行工作组成的；
5. Amdahl定律描述的是：在增加计算资源的情况下，程序在理论上能够实现最高加速比，这个值取决于程序中`可并行组件`与`串行组件`所占的比重。假定`F`是必须被串行执行的那部分，那么根据Amdahl定律，在包含`N`个处理器的机器中，最高加速比为：`speedup <= 1/(F+(1-F)/N)`；
6. 当N趋近于`∞`时，最大加速比趋近于`1/F`;
7. Amdahl定律量化了串行化的效率开销。
   * 在拥有10个处理器的系统中，如果程序中有10%的部分需要串行执行，那么最高的加速比为5.3（53%的使用率）；
   * 在拥有100个处理器的系统中，加速比可以达到9.2（9%的使用率）；
   * 即使拥有无限多的CPU，加速比也不可能是10；
8. 要预测应用程序在某个多处理器系统中将实现多大的加速比，还要找出任务中的串行部分；

## 示例：在各种框架中隐藏的串行部分
1. 要想知道串行部分如何隐藏在应用程序的框架中，可以比较当增加线程时`吞吐量的变化`，并根据观察到的可伸缩性变化来推断串行部分中的差异；
2. Synchronized LinkedList采用`单个锁`来保护整个队列的状态，并且在offer和remove等方法的调用期间都将持有这个锁，整个队列的插入或删除操作都将串行执行;
3. ConcurrentLinkedQueue使用了一种更复杂的`非阻塞队列算法`，该算法使用`原子引用`来更新各个链接指针，只有对指针的更新操作时候需要串行执行；

## Amdahl定律的应用
1. 在评估一个算法时，要考虑算法在数百个或数千个处理器的情况下的性能表现，从而对可能出现的伸缩性局限有一定程度的认识；
2. 锁分解（将1个锁分解为2个锁）并不能充分利用多处理器的能力；
3. 锁分段（将1个锁分解为多个锁）可随着处理器数量的增加而增加；

# 线程引入的开销
1. 单线程程序即不存在线程调度，也不存在同步开销，而且不需要使用锁来保证数据结构的一致性；
2. 在多个线程的调度和协调过程中都需要一定的性能开销；
3. 对于为了提升性能而引入的线程来说，并行带来的`性能提升`必须超过并发导致的`开销`；

## 上下文切换
1. 如果主线程是唯一的线程，那么它基本上不会被调度出去；
2. 如果可运行的线程数大于CPU数，那么操作系统最终会将某个正在运行的线程调度出来，从而使其他线程能够使用CPU，这将导致一次上下文切换；
3. 在这个过程中将保存当前运行线程的执行上下文，并将新调度进来的线程的执行上下文设置为当前上下文；
4. 当线程由于等待某个发生竞争的锁而被阻塞时，JVM通常会将这个线程挂起，并允许它被交换出去。如果线程频繁的发生阻塞，那么它们将无法使用完整的调度时间片；
5. 在程序中发生越多的阻塞（包括I/O阻塞，等待获取发生竞争的锁，或者在条件变量上等待），与CPU密集型程序就会发生越多的上下文切换，从而增加调度开销，并因此降低吞吐量；
6. 无阻塞算法有助于减小上下文切换；
7. 大多数通用的处理器中，上下文切换的开销相当于5000-10000个时钟周期，也就是几微秒；

## 内存同步
同步性能的开销包括多个方面：
1. 在sychronized和volatile提供的可见性保证中可能会使用一些特殊指令，即内存栅栏（Memorry Barrier）。
2. 内存栅栏可以刷新缓存，使缓存无效，刷新硬件的写缓冲，以及停止执行管道。
3. 内存栅栏可能同样会对性能带来间接的影响，因为它们将抑制一些编译优化操作，在内存栅栏中，大多数操作是不能被重排序的；

在评估同步操作带来的性能影响时，区分`有竞争的同步`和`无竞争的同步`非常重要。
1. Synchronized机制针对无竞争的同步进行了优化（volatile通常是有竞争的）
2. 虽然无竞争同步的开销不为0，但它对应用程序整体性能的影响微乎其微。
3. 现代JVM能通过优化来去掉一些不会发生竞争的锁，从而减少不必要的同步开销。如果一个锁对象只能由当前线程访问，那么JVM就可以通过优化来去掉这个锁获取操作，因为另一个线程无法与当前线程在这个锁上同步；
4. 一些更完备的JVM能通过逸出分析(Escape Analysis)找出不会发布到堆的本地对象引用（因此这个引用是线程本地的）；
5. 某个线程的同步可能会影响其他线程的性能。同步会增加共享内存总线上的通信量。总线的宽带是有限的，并且所有的处理器都将共享这条总线，如果多个线程竞争同步带宽，那么所有使用了同步的线程都会受到影响。
>不要过度担心`非竞争同步`带来的开销，这个机制已经非常快了，并且JVM还在进行额外的优化以进一步降低或消除开销。因此，我们应该将优化重点放在那些发生`锁竞争`的地方；
## 阻塞
1. 非竞争的同步完全可以在JVM中进行处理；
2. 竞争的同步可能需要操作系统的介入，从而增加开销；
3. 当在锁上发生竞争时，竞争失败的线程肯定会阻塞；JVM在实现阻塞行为时，可以采用`自旋等待`（Spin-Waiting，指通过循环不断地尝试获取锁，直到成功）；或者通过`操作系统挂起被阻塞的线程`；
4. 当线程无法获取某个锁，或由于在某个条件等待，或在I/O操作上阻塞时，需要被挂起，在这个过程中将包含2次额外的上下文切换，以及所有必要的操作系统操作和缓存操作；

# 减少锁的竞争
1. 串行操作会降低可伸缩性，并且上下文切换也会降低性能；在锁上发生竞争将同时导致这两种问题，因此检所所的竞争能够提高性能和可伸缩性；
2. 在并发程序中，对可伸缩性的最主要的威胁就是独占方式的资源锁；
3. 有2个因素将影响在锁上发生竞争的可能性：`锁的请求频率`，以及`每次持有该锁的时间`；
4. 有3种方式可以降低锁的竞争程度：
   1. 减少锁的持有时间；
   2. 降低锁的请求频率；
   3. 使用带有`协调机制`的独占锁，这些机制允许更高的并发性；
## 缩小锁的范围（快进快出）
1. 降低发生竞争可能性的一种有效方式就是尽可能缩短锁的持有时间。例如，可以将一些与锁无关的代码移出同步代码块，尤其是那些开销比较大的操作，以及可能被阻塞的操作，如I/O操作；
2. 一些需要原子方式执行的操作（例如对某个不变性条件的多个变量进行更新）必须包含在一个同步块中。
## 缩小锁的粒度
1. 另一种减小锁的持有时间的方式是`降低线程请求锁的频率`，从而减小发生竞争的可能性，这可以通过`锁分解`和`锁分段`等技术来实现；
2. 在这些技术中将采用`多个相互独立的锁`来保护独立的状态变量，从而改变这些变量在之前由单个锁来保护的情况；
3. 这些技术能减小锁的粒度，并能实现更高的可伸缩性，然而，使用的锁越多，那么发生`死锁`的风险也就越高；
4. 对竞争适中的锁进行分解时，实际上是将这些锁转变为非竞争的锁，从而有效的提高性能和可伸缩性；
## 锁分段
1. 把1个竞争激烈的锁分解为2个锁时，这2个锁可能都存在激烈的竞争。虽然采用2个线程并发执行能提高一部分可伸缩性，但在一个拥有多个处理器的系统中，仍然无法给可伸缩性带来极大的提高；
2. 在某些情况下，可以将锁分段技术进一步扩展为`对一组独立对象上的锁进行分解`，这种情况呗成为锁分段；
3. ConcurrentHashMap提通过16个锁的数组老保护16个hash桶，假设hash函数具有合理的分布性，并且key能够实现均匀分布，那么这大约能把对于锁的请求减少到原来的1/16；正式这项技术使得ConcurrentHashMap能够支持高达16个并发的写入；
4. 锁分段的另一个劣势在于：与采用单个锁来实现独占访问相比，要获得多个锁来实现独占访问将更加困难并且开销更高；
## 避免热点域
## 一些替代独占锁的方法
## 监测CPU的利用率
## 向对象池说No

# 示例：比较Map的性能
# 减少上下文切换的开销